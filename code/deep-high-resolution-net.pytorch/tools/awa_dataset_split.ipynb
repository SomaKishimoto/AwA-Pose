{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import pprint\n",
    "import shutil\n",
    "import pickle\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "#from tensorboardX import SummaryWriter\n",
    "\n",
    "import _init_paths\n",
    "from config import cfg\n",
    "from config import update_config\n",
    "from core.loss import JointsMSELoss\n",
    "from core.function import train\n",
    "from core.function import validate\n",
    "from utils.utils import get_optimizer\n",
    "from utils.utils import save_checkpoint\n",
    "from utils.utils import create_logger\n",
    "from utils.utils import get_model_summary\n",
    "\n",
    "import dataset\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['annotations', 'images', 'categories', 'info'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/u/snaha/v6/dataset/AWA/Animals_with_Attributes2/quadruped_keypoints/coco_format/dataset.pickle', 'rb') as handle:\n",
    "    dataset = pickle.load(handle)\n",
    "    \n",
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'width': 1024,\n",
       " 'height': 768,\n",
       " 'filename': 'antelope_10002.jpg',\n",
       " 'id': 'antelope_10002'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['antelope',\n",
       " 'bobcat',\n",
       " 'buffalo',\n",
       " 'chihuahua',\n",
       " 'collie',\n",
       " 'cow',\n",
       " 'dalmatian',\n",
       " 'deer',\n",
       " 'elephant',\n",
       " 'fox',\n",
       " 'german+shepherd',\n",
       " 'giant+panda',\n",
       " 'giraffe',\n",
       " 'grizzly+bear',\n",
       " 'hippopotamus',\n",
       " 'horse',\n",
       " 'leopard',\n",
       " 'lion',\n",
       " 'moose',\n",
       " 'otter',\n",
       " 'ox',\n",
       " 'persian+cat',\n",
       " 'pig',\n",
       " 'polar+bear',\n",
       " 'rabbit',\n",
       " 'raccoon',\n",
       " 'rhinoceros',\n",
       " 'sheep',\n",
       " 'siamese+cat',\n",
       " 'skunk',\n",
       " 'squirrel',\n",
       " 'tiger',\n",
       " 'weasel',\n",
       " 'wolf',\n",
       " 'zebra']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/u/snaha/v6/dataset/AWA/Animals_with_Attributes2/quadruped_keypoints/Annotations/'\n",
    "list_subfolders_with_paths = [f.path for f in os.scandir(path) if f.is_dir()]\n",
    "\n",
    "animal_list = []\n",
    "\n",
    "for animal in list_subfolders_with_paths:\n",
    "    animal_folder = animal#os.path.join(path, animal)\n",
    "    animal_list.append(animal_folder.split('/')[-1])\n",
    "    \n",
    "animal_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train instances =  8877 8877\n",
      "Number of test instances =  1153 1153\n",
      "Number of train instances =  8833 8833\n",
      "Number of test instances =  1197 1197\n",
      "Number of train instances =  8813 8813\n",
      "Number of test instances =  1217 1217\n",
      "Number of train instances =  8838 8838\n",
      "Number of test instances =  1192 1192\n",
      "Number of train instances =  8852 8852\n",
      "Number of test instances =  1178 1178\n"
     ]
    }
   ],
   "source": [
    "def generate_split(animal_list, dataset):\n",
    "    \n",
    "    rand_inds = np.arange(len(animal_list)).tolist()\n",
    "    random.shuffle(rand_inds)    \n",
    "    anim_list = []\n",
    "    for ind in rand_inds:\n",
    "        anim_list.append(animal_list[ind])\n",
    "    dataset_train = dict()\n",
    "    dataset_test = dict() \n",
    "    \n",
    "    annotations_train = []\n",
    "    annotations_test = []\n",
    "    \n",
    "    images_train = []\n",
    "    images_test = []\n",
    "    \n",
    "    train_animals = anim_list[:-4]\n",
    "    test_animal = anim_list[-4:]\n",
    "    \n",
    "    for anno in dataset['annotations']:\n",
    "        if anno['animal'] in test_animal:\n",
    "            annotations_test.append(anno)\n",
    "        else:\n",
    "            annotations_train.append(anno)\n",
    "        \n",
    "    for anno in dataset['images']:\n",
    "        if anno['id'].split('_')[0] in test_animal:\n",
    "            images_test.append(anno)\n",
    "        else:\n",
    "            images_train.append(anno)        \n",
    "                \n",
    "    dataset_train['annotations'] = annotations_train\n",
    "    dataset_test['annotations'] = annotations_test\n",
    "    \n",
    "    dataset_train['images'] = images_train\n",
    "    dataset_test['images'] = images_test\n",
    "    \n",
    "    dataset_train['categories'] = dataset['categories']\n",
    "    dataset_test['categories'] = dataset['categories']    \n",
    "    \n",
    "    dataset_train['info'] = dataset['info']\n",
    "    dataset_test['info'] = dataset['info']       \n",
    "    \n",
    "    return train_animals, test_animal, dataset_train, dataset_test\n",
    "\n",
    "for i in range(5):\n",
    "    train_animals, test_animals, dataset_train, dataset_test = generate_split(animal_list, dataset)\n",
    "    #test_animals\n",
    "    print('Number of train instances = ', len(dataset_train['images']), len(dataset_train['annotations']))\n",
    "    print('Number of test instances = ', len(dataset_test['images']), len(dataset_test['annotations']))\n",
    "    \n",
    "    with open('/u/snaha/v6/dataset/AWA/Animals_with_Attributes2/quadruped_keypoints/coco_format/dataset_train_' + str(i+1) + '.pickle', 'wb') as handle:\n",
    "        pickle.dump(dataset_train, handle, protocol=pickle.HIGHEST_PROTOCOL)    \n",
    "        \n",
    "    with open('/u/snaha/v6/dataset/AWA/Animals_with_Attributes2/quadruped_keypoints/coco_format/dataset_val_' + str(i+1) + '.pickle', 'wb') as handle:\n",
    "        pickle.dump(dataset_test, handle, protocol=pickle.HIGHEST_PROTOCOL)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [.24, .72, .72, .18, .62, .23, .56, .26, .38, .28, .29, .48, .23, .60, .47, .24, .72, .72, .18, .62, .23, .56, .26, .38, .28, .29, .48, .23, .60, .47, .18, .62, .23, .56, .26, .38, .28, .29, .48]\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
